{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbc6767",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-26126dc49caf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfeature_extraction\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpre_processing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from commonfunctions import *\n",
    "import joblib\n",
    "import imageio as iio\n",
    "import cv2\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray  # only needed for incorrectly saved images\n",
    "from skimage.measure import regionprops\n",
    "from skimage import data, color, feature,morphology\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from feature_extraction import *\n",
    "from pre_processing import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import LinearSVC,SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# The images are RGB.\n",
    "img_channels = 3\n",
    "nb_classes = 9\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "data = datagen.flow_from_directory('ACdata_base',\n",
    "                                    target_size=(500, 500),\n",
    "                                    batch_size=73139,\n",
    "                                    class_mode='sparse',\n",
    "                                   color_mode='grayscale',\n",
    "                                    shuffle=True,\n",
    "                                    seed=42 )\n",
    "X , y = data.next()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=11);\n",
    "#X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.50, random_state=11);\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2960674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefe4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_train=[pre_process(patch) for patch in X_train] # de bet7awel 2el training set le binary fa law feature sha8ala 3ala binary hanesta5dem da\n",
    "cropped_images=[crop_image(patch) for patch in pre_processed_train]\n",
    "resized_cropped_images=[cv2.resize(np.array(cropped, dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA) for cropped in cropped_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0bbcf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hough=np.array([ get_max_theta(img) for img in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4d1dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "GABOR=np.array([gabor_filter(img.reshape(img.shape[0],img.shape[1])) for img in X_train]).reshape(-1,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f7370",
   "metadata": {},
   "outputs": [],
   "source": [
    "GLCM=np.array([GLCM_features(img) for img in resized_cropped_images]).reshape(-1,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f60357",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl=np.array([LVL(img) for img in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363655db",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPQ=[lpq(img.reshape(img.shape[0],img.shape[1]),winSize=10) for img in resized_cropped_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d831e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LPQ=np.array(LPQ)\n",
    "print(LPQ.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e03b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hu_moments=np.array([hu_moments_func(img)for img in resized_cropped_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hu_moments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbp=np.array([LBP(img,numPoints=24,radius=3,method=\"uniform\",window=500) for img in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones=np.array([count_ones(img) for img in resized_cropped_images]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a020d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "corners=np.array([get_corners(img) for img in X_train]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_v=np.array([cv2.resize(get_max_vertical(patch), (50,1), interpolation = cv2.INTER_AREA) for patch in resized_cropped_images]).reshape(-1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24726e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonal=np.array([project_image_diagonal(patch) for patch in X_train]).reshape(-1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3337e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "center_of_masses=np.array([center_of_mass(img) for img in resized_cropped_images]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f99619",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for gray in X_train:\n",
    "    print(gray.shape)\n",
    "    values.append(HVSL(np.uint8(gray)))\n",
    "print(np.asarray(values).reshape(-1,1))\n",
    "values=np.asarray(values).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f8c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import data, color, feature\n",
    "patches_hog = np.array([feature.hog(patch,cells_per_block=(3, 3),pixels_per_cell=(150, 150), orientations=7) for patch in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3c90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patches_hog.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fel paper kan 3ayezna nda5al skeleton image 3ala histogram of gradienta fa garabna neda5alo 3al hog\n",
    "patches_hog_skeleton = np.array([feature.hog(morphology.skeletonize(patch).astype(int),cells_per_block=(3, 3),pixels_per_cell=(150, 150), orientations=6) for patch in resized_cropped_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edf7fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_line_feature2=np.array([HPP_Skeletonize(patch) for patch in resized_cropped_images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f6e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_line_feature=np.array([cv2.resize(HPP(patch), (50,1), interpolation = cv2.INTER_AREA) for patch in resized_cropped_images]).reshape(-1,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5448d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_array=np.concatenate((np.array(values).reshape(-1,1),np.array(center_of_masses).reshape(-1,1),base_line_feature2.reshape(-1,1),ones),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb61bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base_line_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3b71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72ac026",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_hog=np.concatenate((patches_hog,patches_hog_skeleton,combined_array,GLCM,lbp,GABOR),axis=-1)\n",
    "#combined_hog=LPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=np.mean(combined_hog)\n",
    "std=np.std(combined_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ce31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_hog=(combined_hog-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8379ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_hog.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0bbd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "combined_hog=pca.fit_transform(combined_hog)\n",
    "filename = 'pca_model.sav'\n",
    "joblib.dump(pca, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a25b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(25,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(9,activation='softmax'))\n",
    "model.compile(optimizer='adam', metrics=['accuracy'],loss='categorical_crossentropy')\n",
    "print(combined_hog.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath=\"weights2.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1,save_best_only=True, mode='max')\n",
    "C = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37751086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(combined_hog,dummy_y, epochs=200, batch_size=100,callbacks=C, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acaa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('gaussian',cross_val_score(GaussianNB(), combined_hog, y_train))\n",
    "\n",
    "grid = GridSearchCV(LinearSVC(), {'C': [1.0, 2.0, 4.0, 8.0]})\n",
    "grid.fit(combined_hog, y_train)\n",
    "print('svm',grid.best_score_)\n",
    "# bensave 2el model 3ashan mane3melsh train kol shwaya\n",
    "filename = 'final_svm.sav'\n",
    "joblib.dump(grid, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=11)\n",
    "classifier.fit(combined_hog, y_train)\n",
    "print('gaussian',cross_val_score(classifier, combined_hog, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(50, 20), random_state=1,    early_stopping=True)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50, 25))\n",
    "print('gaussian',np.mean(cross_val_score(clf, combined_hog, y_train)))\n",
    "clf.fit(combined_hog, y_train)\n",
    "filename = 'final_nn.sav'\n",
    "joblib.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f39b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn = MLPClassifier(hidden_layer_sizes=(50, 25))\n",
    "clf_for=RandomForestClassifier()\n",
    "clf_svm = GridSearchCV(SVC(kernel='linear',probability=True), {'C': [1.0, 2.0, 4.0, 8.0]})\n",
    "eclf2 = VotingClassifier(estimators=[\n",
    "         ('nn', clf_nn),('svm',clf_svm)],\n",
    "         voting='soft',\n",
    "         flatten_transform=True)\n",
    "print('gaussian',np.mean(cross_val_score(eclf2, combined_hog, y_train)))\n",
    "eclf2.fit(combined_hog, y_train)\n",
    "filename = 'final_voting.sav'\n",
    "joblib.dump(eclf2, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8159e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "clf4="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c025c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=joblib.load('final_voting.sav')\n",
    "model_pca=joblib.load('pca_model.sav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7f9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_image):\n",
    "    start=time.time()\n",
    "    binarized_image=cv2.resize(np.array(crop_image(pre_process(test_image)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA)\n",
    "    values=HVSL(np.uint8(test_image))\n",
    "    center_of_masses=center_of_mass(binarized_image)\n",
    "    base_line_feature2=HPP_Skeletonize(binarized_image)\n",
    "    ones=count_ones(binarized_image)\n",
    "    combined_array=np.array([values,center_of_masses,base_line_feature2,ones]).reshape(1,-1)\n",
    "    GLCM=np.array(GLCM_features(binarized_image)).reshape(1,-1)\n",
    "    GABOR=gabor_filter(test_image.reshape(test_image.shape[0],test_image.shape[1])).reshape(1,-1)\n",
    "    lbp=LBP(test_image,numPoints=24,radius=3,method=\"uniform\",window=500).reshape(1,-1)\n",
    "    patches_hog_skeleton=feature.hog(morphology.skeletonize(binarized_image).astype(int),cells_per_block=(3, 3),pixels_per_cell=(150, 150), orientations=6).reshape(1,-1)\n",
    "    patches_hog=feature.hog(test_image,cells_per_block=(3, 3),pixels_per_cell=(150, 150), orientations=7).reshape(1,-1)\n",
    "    feature_vector=np.concatenate((patches_hog.reshape(1,-1),patches_hog_skeleton.reshape(1,-1),combined_array.reshape(1,-1),GLCM.reshape(1,-1),lbp,GABOR),axis=-1).reshape(1,-1)\n",
    "    #print(feature_vector.shape)\n",
    "    feature_vector=(feature_vector-mean)/std\n",
    "    pca_output=model_pca.transform(feature_vector)\n",
    "    prediction=model.predict(pca_output)\n",
    "    end=time.time()\n",
    "    #print(prediction)\n",
    "    print(end-start)\n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5816af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[predict(img) for img in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc3e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct=(np.array(predictions).reshape(-1).astype(\"int\")==y_test)\n",
    "print(np.array(predictions).shape)\n",
    "print(correct.shape)\n",
    "print(\"accuracy\",sum(correct)/correct.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01f332c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_vote(img):\n",
    "    model_HVSL=joblib.load('HVSL.sav')\n",
    "    model_HOG=joblib.load('hog.sav')\n",
    "    model_hist=joblib.load('HIST.sav')\n",
    "    model_HPP=joblib.load('HPP.sav')\n",
    "    model_HOG_SKELETON=joblib.load('hog_skeletonize.sav')\n",
    "    model_hist_skeleton=joblib.load('HIST_Skeleton.sav')\n",
    "    model_center=joblib.load('center_of_mass.sav')\n",
    "    model_hpp_skeletonize=joblib.load('HPP_Skeletonize.sav')\n",
    "    model_max_v=joblib.load('MAX_V.sav')\n",
    "    model_combined=joblib.load('combined.sav')\n",
    "    model_lbp=joblib.load('LBP.sav')\n",
    "    model_hog_combined=joblib.load('hog_combined_nn.sav')\n",
    "    model_pca=joblib.load('pca_model.sav')\n",
    "    glcm=np.array(GLCM_features(cv2.resize(np.array(crop_image(pre_process(img)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA))).reshape(-1,12)\n",
    "    #vote_max_v=model_max_v.predict(np.array([get_max_vertical(crop_image(pre_process(img)))]).reshape(1,-1))\n",
    "    #combined_array=np.concatenate((max_v,np.array(values).reshape(-1,1),center_of_masses,base_line_feature2.reshape(-1,1)),axis=-1)\n",
    "    lbp_feature=LBP(cv2.resize(img, (500,500), interpolation = cv2.INTER_AREA),radius=3,numPoints=24,method=\"uniform\",window=500).reshape(1,-1)\n",
    "    #vote_lbp=model_lbp.predict(lbp_feature)\n",
    "    max_v=cv2.resize(np.array(get_max_vertical(cv2.resize(np.array(crop_image(pre_process(img)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA)), dtype='uint8'), (50,1), interpolation = cv2.INTER_AREA)\n",
    "    combined_array=np.array([HVSL(np.uint8(img)),center_of_mass(cv2.resize(np.array(crop_image(pre_process(img)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA)),HPP_Skeletonize(cv2.resize(np.array(crop_image(pre_process(img)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA)),get_corners(img),count_ones(cv2.resize(np.array(crop_image(pre_process(img)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA))]).reshape(1, -1)\n",
    "    #print(combined_array.shape)\n",
    "    #vote_combined=model_combined.predict(combined_array)\n",
    "    #vote_hpp_skeletonize=model_center.predict(np.array([HPP_Skeletonize(crop_image(pre_process(img)))]).reshape(1,-1))\n",
    "    #vote_center=model_center.predict(np.array(center_of_mass(cv2.resize(np.array(crop_image(pre_process(img)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA))[0]).reshape(1,-1))\n",
    "    #vote_HVSL=model_HVSL.predict(np.array([HVSL(np.uint8(img))]).reshape(1,-1))\n",
    "    #print(vote_HVSL)\n",
    "    Gabor=gabor_filter(img.reshape(img.shape[0],img.shape[1])).reshape(1,32)\n",
    "    base_line_features=cv2.resize(HPP(cv2.resize(np.array(crop_image(pre_process(img)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA)), (50,1), interpolation = cv2.INTER_AREA).reshape(1,50)\n",
    "    features_hog=feature.hog(cv2.resize(img, (64,48), interpolation = cv2.INTER_AREA), cells_per_block=(2, 2),pixels_per_cell=(16, 16), orientations=6).reshape(1,-1)\n",
    "    features_hog_skeleton=feature.hog(morphology.skeletonize(cv2.resize(np.array(crop_image(pre_process(img)),dtype=\"uint8\"), (64,48), interpolation = cv2.INTER_AREA)).astype(\"int\"),cells_per_block=(2, 2),pixels_per_cell=(16, 16), orientations=6).reshape(1,-1)\n",
    "    #vote_hog=model_HOG.predict(features_hog)\n",
    "    #vote_hist=model_hist.predict(get_histogram_of_gradients(pre_process(img)).reshape(1,-1))\n",
    "    #print(vote_hist)\n",
    "    #vote_HPP=model_HPP.predict(HPP(cv2.resize(np.array(crop_image(pre_process(img)), dtype='uint8'), (500,500), interpolation = cv2.INTER_AREA)).reshape(1,-1))\n",
    "    #print(vote_HPP)\n",
    "    combine_array_hog=np.concatenate((features_hog,combined_array,lbp_feature,features_hog_skeleton,base_line_features,glcm,max_v,Gabor),axis=-1).reshape(1,-1)\n",
    "    #print(pca.transform(combine_array_hog).shape)\n",
    "    #print(combine_array_hog.shape)\n",
    "    pca_output=model_pca.transform(combine_array_hog)\n",
    "    vote_hog_combined=model_hog_combined.predict(combine_array_hog)\n",
    "    #vote_HOG_SKELETON=model_HOG_SKELETON.predict(features_hog_skeleton)\n",
    "    #vote_hist_skeleton=model_hist_skeleton.predict(get_histogram_of_gradients(morphology.skeletonize(np.array(pre_process(img),dtype=\"uint8\")).astype(\"int\")).reshape(1,-1))\n",
    "    #print(vote_hist_skeleton)\n",
    "    #votes=np.array([vote_HVSL,vote_hog,vote_HPP,vote_HOG_SKELETON]).reshape(-1).astype(\"int\")\n",
    "    votes=np.array([vote_hog_combined]).reshape(-1).astype(\"int\")\n",
    "    #print(votes)\n",
    "    return np.bincount(votes).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images([X_test[0]])\n",
    "print(\"hehhhhh\",get_max_vote(X_test[0]))\n",
    "print(\"saaaa7\",y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60255087",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values=[get_max_vote(img) for img in X_test]\n",
    "print(test_values)\n",
    "print(y_test.astype(\"int\"))\n",
    "correct=test_values==y_test\n",
    "show_images([y_test[test_values!=y_test]])\n",
    "#print(np.bincount(y_test[test_values!=y_test]).argmax())\n",
    "print(\"accuracy=\",np.sum(correct)/correct.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a91a0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"accuracy=\",np.sum(correct)/correct.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e212ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[(1,2,3,4),(5,6,7,8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41015e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b392e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5af63",
   "metadata": {},
   "outputs": [],
   "source": [
    "329/334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd40b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(X_test[np.array(predictions).reshape(-1).astype(\"int\")!=y_test])\n",
    "print(y_test[np.array(predictions).reshape(-1).astype(\"int\")!=y_test])\n",
    "print(np.array(predictions).reshape(-1).astype(\"int\")[np.array(predictions).reshape(-1).astype(\"int\")!=y_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843ae10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
